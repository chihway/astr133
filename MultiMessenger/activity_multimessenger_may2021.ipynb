{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-messenger Gravitational Wave Astronomy\n",
    "\n",
    "Author: Jose Maria Ezquiaga\n",
    "\n",
    "In this activity we are going to explore the future of multi-messenger gravitational wave astronomy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.integrate import quad "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LISA super-massive black hole binaries\n",
    "\n",
    "[LISA](https://www.lisamission.org/articles/lisa-mission/lisa-mission-gravitational-universe) is a future gravitational wave detector from space. It will detect sources at lower frequencies than current ground-based detectors, around the milli-Hertz band. \n",
    "\n",
    "Among many cool sources, LISA will detect super-massive black hole binaries. These black holes are more than a million times heavier than the Sun.\n",
    "\n",
    "In the plot below you can see the three different types of gravitational wave detector sensitivities as a function of frequency and their possible sources:\n",
    "\n",
    "<img src='https://upload.wikimedia.org/wikipedia/commons/a/af/Gravitational-wave_detector_sensitivities_and_astrophysical_gravitational-wave_sources.png' alt='Alt text' title='Title text' />\n",
    "\n",
    "_Note:_ PTA means pulsar timing array. They aim at detecting gravitational waves from the distortions of the timing of known milli-second pulsars in the galaxy. This is very cool science. I recommend investigating about them!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Super-massive black hole catalogs\n",
    "\n",
    "We are going to work with three different catalogs of super-massive black holes with multi-messenger signals. Each catalog correspond to a different formation model (this is quite technical, but if you want to research the article explaining them is [this one](https://arxiv.org/abs/1601.07112)). \n",
    "\n",
    "These catalogs provide a list of luminosity distances, relative errors (obtained from the GW) and redshifts (obtained from the electromagnetic signal). \n",
    "\n",
    "_Note:_ this is simulated data since LISA is still far from launching. It will do it in $\\sim$2034. Maybe you will be leading the mission by that time :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog1 = np.genfromtxt('smbh_lisa_catalogs/heavy_no_delays.txt')\n",
    "dL_catalog1 = catalog1[:,0] #luminosity distance in Mpc\n",
    "edL_catalog1 = catalog1[:,1] # relative error in luminosity distance\n",
    "z_catalog1 = catalog1[:,2] # redshift\n",
    "\n",
    "catalog2 = np.genfromtxt('smbh_lisa_catalogs/heavy_Q3.txt')\n",
    "dL_catalog2 = catalog2[:,0] #luminosity distance in Mpc\n",
    "edL_catalog2 = catalog2[:,1] # relative error in luminosity distance\n",
    "z_catalog2 = catalog2[:,2] # redshift\n",
    "\n",
    "catalog3 = np.genfromtxt('smbh_lisa_catalogs/popIII.txt')\n",
    "dL_catalog3 = catalog3[:,0] #luminosity distance in Mpc\n",
    "edL_catalog3 = catalog3[:,1] # relative error in luminosity distance\n",
    "z_catalog3 = catalog3[:,2] # redshift"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the luminosity distance with its erros for the first catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.errorbar(z_catalog1,dL_catalog1/1000,yerr=dL_catalog1*edL_catalog1/1000,fmt='o', ms =3,capsize=2,linewidth=0.7,label='Catalog 1')\n",
    "plt.errorbar(z_catalog2,dL_catalog2/1000,yerr=dL_catalog2*edL_catalog2/1000,fmt='^', ms =3,capsize=2,linewidth=0.7,label='Catalog 2')\n",
    "plt.errorbar(z_catalog3,dL_catalog3/1000,yerr=dL_catalog3*edL_catalog3/1000,fmt='s', ms =3,capsize=2,linewidth=0.7,label='Catalog 3')\n",
    "plt.xlabel(r'$z$')\n",
    "plt.ylabel(r'$d_L\\,\\mathrm{[Gpc]}$')\n",
    "plt.grid(0.4)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measuring distance in the universe\n",
    "\n",
    "In order to measure distances in the universe one needs a standard reference to compare to, in the same way that when you want to measure your height you need a meter. For example, Supernova type IA provide this reference scale since their intrinsic luminosity $L$ is known (or at least we know how to calibrate it). Then, since the flux of energy $F$ scales inversely with the square of luminosity distance,\n",
    "\\begin{equation}\n",
    "F= \\frac{L}{4\\pi d_L^2}\\,.\n",
    "\\end{equation}\n",
    "we can infer directly $d_L$ form the measurtement of $F$. SNIA are thus _standard sirens_.\n",
    "\n",
    "In gravitational wave astronomy instead of measuring fluxes on gets directly the amplitude of the signal. Such amplitude (technically known as strain $h$) is inversely proportional to the luminosity distance\n",
    "\\begin{equation}\n",
    "h\\propto \\mathcal{M_c}^{5/3}/ d_L\\,,\n",
    "\\end{equation}\n",
    "and depends also on the chirp mass, which is a combiantion of the component masses of the binary $\\mathcal{M}_c=(m_1m_2)^{3/5}/(m_1+m_2)^{1/5}$. Since the masses can be obtained from the chirp of the signal, i.e. its frequency evolution, the GW amplitude provides a direct measurement of $d_L$. This is why GWs are _standard sirens_.\n",
    "\n",
    "## Luminosity distance\n",
    "\n",
    "The luminosity distance-redshift relation is determined by the cosmological model. For a universe with only matter and dark energy (good description for $z<10$), the luminosity distance is determined by\n",
    "\\begin{equation}\n",
    "d_L(z)=(1+z)\\int_0^z\\frac{cdz}{H(z)}\\,,\n",
    "\\end{equation}\n",
    "where $c$ is the speed of light and the Hubble parameter, which measures the rate of expansion $H=\\dot{a}/a$, follows\n",
    "\\begin{equation}\n",
    "H(z)=H_0\\sqrt{\\Omega_M(1+z)^3+\\Omega_\\Lambda}\\,.\n",
    "\\end{equation}\n",
    "Here $\\Omega_M$ and $\\Omega_\\Lambda$ are the present, fractional energy density of matter (dark matter + ordinary matter) and dark energy respectively. \n",
    "\n",
    "A nice reference describing the different distances in cosmology is [Hogg'99](https://arxiv.org/pdf/astro-ph/9905116.pdf).\n",
    "\n",
    "_Note:_ for a universe with no curvature, $1=\\Omega_M+\\Omega_\\Lambda$\n",
    "\n",
    "_Note:_ if you like integrals and special mathematical functions, you can try to solve this one analytically. Explore! \n",
    "\n",
    "You can also play with this cosmology in [Mathematica](https://demonstrations.wolfram.com/CosmologyOfEinsteinDeSitterUniverse/) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def c_Hz(z,H0,oM,oDE):\n",
    "    #H0 in units of km/s/Mpc\n",
    "    c = 3.0e5 # speed of light km/s\n",
    "    return c/(H0*np.sqrt(oM*np.power(1+z,3)+oDE))\n",
    "\n",
    "def dL_LCDM(z,H0,oM,oDE):\n",
    "    return (1+z)*quad(c_Hz,0,z,args=(H0,oM,oDE))[0] #Mpc\n",
    "dL_LCDM = np.vectorize(dL_LCDM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H0_guess = 67. # km/s/Mpc\n",
    "oM_guess = 0.3 \n",
    "oDE_guess = 0.7\n",
    "\n",
    "zs = np.linspace(0,6,100)\n",
    "dL_guess = dL_LCDM(zs,H0_guess,oM_guess,oDE_guess)/1000 # Gpc\n",
    "#Plot\n",
    "plt.plot(zs,dL_guess,label='Fit')\n",
    "plt.errorbar(z_catalog1,dL_catalog1/1000,yerr=dL_catalog1*edL_catalog1/1000,fmt='o', ms =3,capsize=2,linewidth=0.7,label='Catalog 1')\n",
    "plt.xlabel(r'$z$')\n",
    "plt.ylabel(r'$d_L\\,\\mathrm{[Gpc]}$')\n",
    "plt.grid(0.4)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Activity\n",
    "\n",
    "Find the parameters $H_0$ and $\\Omega_M$ (use that $\\Omega_\\Lambda = 1 - \\Omega_M$) that best fit the data for each of the catalogs.\n",
    "\n",
    "You can use either a visual fit, least squares, maximum likelihood estimation... Can you get how large is their uncertainty?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How can you learn more about GWs?\n",
    "\n",
    "The [GW-Open Science center](https://www.gw-openscience.org/about/) has a lot of great resources, including tutorials that will let you [discovery GWs on your own](https://www.gw-openscience.org/GW150914data/GW150914_tutorial.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
